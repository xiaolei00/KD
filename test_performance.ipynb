{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1f2ca7-e8bf-4722-854f-e1f9ebda7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b09ba5c-f00a-4d37-80ff-a5eca08c99ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homec/xiaolei/anaconda3/envs/pytorchEnv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms as Transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68842954-c4da-4afd-b43d-878f733a5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归删除指定目录下的.ipynb_checkpoints文件夹\n",
    "def remove_ipynb_checkpoints(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for dir in dirs:\n",
    "            if dir == \".ipynb_checkpoints\":\n",
    "                folder_path = os.path.join(root, dir)\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"Deleted: {folder_path}\")\n",
    "\n",
    "class SwinTransformerTeacher(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(SwinTransformerTeacher, self).__init__()\n",
    "        self.model = timm.create_model('swin_base_patch4_window7_224')\n",
    "        self.num_features = num_features\n",
    "        self.feat = nn.Linear(1024, num_features) if num_features > 0 else None\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        patch_embed = self.model.patch_embed  # Patch Embedding 层\n",
    "        pos_drop = self.model.pos_drop\n",
    "        layers = self.model.layers  # 基本层（包含多个 SwinBlock）\n",
    "        \n",
    "        x = patch_embed(x)  # Patch Embedding\n",
    "        x = pos_drop(x)\n",
    "        for layer in layers:  # 逐个通过 BasicLayer\n",
    "            # x = layer(x)\n",
    "            # features.append(x)\n",
    "            for block in layer.blocks:\n",
    "                x = block(x)\n",
    "            features.append(x)\n",
    "            if layer.downsample is not None:\n",
    "                x = layer.downsample(x)\n",
    "        return tuple(features)\n",
    "\n",
    "    def forward_specific_stage(self, x, stage, down_sample=True):\n",
    "        BS, L, C = x.shape\n",
    "\n",
    "        if stage == 2:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-4].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-3].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 3:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-3].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-2].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 4:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-2].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-1].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "            norm_layer = self.model.norm\n",
    "            x = norm_layer(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "\n",
    "'''\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        features.append(stage3_out)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        features.append(stage4_out)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "'''\n",
    "\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        # 修改 layer1 和 layer2，向每个残差块中的 ReLU 前加上 InstanceNorm2d\n",
    "        self._modify_layer(self.model.layer1)\n",
    "        self._modify_layer(self.model.layer2)\n",
    "        self._modify_layer_stride(self.model.layer4[0].conv2, self.model.layer4[0].downsample[0])\n",
    "        # 输出设置\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        features.append(stage3_out)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        features.append(stage4_out)\n",
    "        return tuple(features)\n",
    "\n",
    "    def _modify_layer(self, layer):\n",
    "        \"\"\"\n",
    "        在每个残差块中的 ReLU 前加上 InstanceNorm2d 操作。\n",
    "        \"\"\"\n",
    "        for block in layer:\n",
    "            # 修改 conv1 和 conv2 之后的 ReLU，将 InstanceNorm2d 放在 ReLU 前面\n",
    "            # 对于每个残差块，将 InstanceNorm2d 加入到 ReLU 之前\n",
    "            block.act3 = nn.Sequential(\n",
    "                nn.InstanceNorm2d(block.conv3.out_channels, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def _modify_layer_stride(self, last_layer, last_layer_downsample):\n",
    "        # 在最后一层将stride改为1\n",
    "        last_layer.stride = (1, 1)\n",
    "        last_layer_downsample.stride = (1, 1)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "\n",
    "'''\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        # 修改 layer1 和 layer2，向每个残差块中的 ReLU 前加上 InstanceNorm2d\n",
    "        self._modify_layer(self.model.layer1)\n",
    "        self._modify_layer(self.model.layer2)\n",
    "        self._modify_layer_stride(self.model.layer4[0].conv2, self.model.layer4[0].downsample[0])\n",
    "        # 进行特征映射\n",
    "        self.projector_1 = AttentionProjector(student_dims=256, teacher_dims=128, hw_dims=(56, 56), pos_dims=128, window_shapes=(1, 1), self_query=True, \n",
    "                                 softmax_scale=5.0, num_heads=4)\n",
    "        self.projector_2 = AttentionProjector(student_dims=512, teacher_dims=256, hw_dims=(28, 28), pos_dims=256, window_shapes=(1, 1), self_query=True, \n",
    "                                         softmax_scale=5.0, num_heads=8)\n",
    "        self.projector_3 = AttentionProjector(student_dims=1024, teacher_dims=512, hw_dims=(14, 14), pos_dims=512, window_shapes=(1, 1), self_query=True, \n",
    "                                         softmax_scale=5.0, num_heads=16)\n",
    "        self.projector_4 = AttentionProjector(student_dims=2048, teacher_dims=1024, hw_dims=(7, 7), pos_dims=1024, window_shapes=(1, 1), self_query=True, \n",
    "                                 softmax_scale=5.0, num_heads=32)\n",
    "        # 输出设置\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        # features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        # features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        student_feature_proj3 = self.projector_3(stage3_out)\n",
    "        features.append(student_feature_proj3)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        student_feature_proj4 = self.projector_4(stage4_out)\n",
    "        features.append(student_feature_proj4)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def extract_feat_proj(self, x):\n",
    "        features = []\n",
    "        student_features = self.extract_feat(x)\n",
    "        # student_feature_proj1 = self.projector_1(student_features[0])\n",
    "        # features.append(student_feature_proj1)\n",
    "        # student_feature_proj2 = self.projector_2(student_features[1])\n",
    "        # features.append(student_feature_proj2)\n",
    "        student_feature_proj3 = self.projector_3(student_features[2])\n",
    "        features.append(student_feature_proj3)\n",
    "        student_feature_proj4 = self.projector_4(student_features[3])\n",
    "        features.append(student_feature_proj4)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def _modify_layer(self, layer):\n",
    "        \"\"\"\n",
    "        在每个残差块中的 ReLU 前加上 InstanceNorm2d 操作。\n",
    "        \"\"\"\n",
    "        for block in layer:\n",
    "            # 修改 conv1 和 conv2 之后的 ReLU，将 InstanceNorm2d 放在 ReLU 前面\n",
    "            # 对于每个残差块，将 InstanceNorm2d 加入到 ReLU 之前\n",
    "            block.act3 = nn.Sequential(\n",
    "                nn.InstanceNorm2d(block.conv3.out_channels, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def _modify_layer_stride(self, last_layer, last_layer_downsample):\n",
    "        # 在最后一层将stride改为1\n",
    "        last_layer.stride = (1, 1)\n",
    "        last_layer_downsample.stride = (1, 1)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "'''\n",
    "class Data_Processor(object):\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transformer = Transforms.Compose([\n",
    "            Transforms.Resize((self.height, self.width)),\n",
    "            Transforms.ToTensor(),\n",
    "            Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.transformer(img).unsqueeze(0)\n",
    "\n",
    "data_processor = Data_Processor(height=224, width=224)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# swin_model = SwinTransformerTeacher(num_features=512).cuda()\n",
    "# swin_model.eval()\n",
    "\n",
    "# resnet_model = ResNetStudent(num_features=512).cuda()\n",
    "# resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8374c7-90cf-4829-9caf-ddc46609750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homec/xiaolei/anaconda3/envs/pytorchEnv/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484657607/work/aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_model = SwinTransformerTeacher(num_features=512).cuda()\n",
    "swin_model.eval()\n",
    "\n",
    "resnet_model = ResNetStudent(num_features=512).cuda()\n",
    "resnet_model.eval()\n",
    "\n",
    "# swin_transformer\n",
    "weight_path = '/homec/xiaolei/projects/ISR/weights/swin_base_patch4_window7_224.pth'\n",
    "weight = torch.load(weight_path)\n",
    "swin_model.load_state_dict(weight['state_dict'], strict=True)\n",
    "\n",
    "# 残差网络\n",
    "weight_path = 'weights/student_model_base5_strong_reid_mmd_mse_loss/best_student_model.pth'\n",
    "weight = torch.load(weight_path)\n",
    "resnet_model.load_state_dict(weight, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c3fd8c-f85c-468a-8dc1-7649b52eeb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_model size (MB): 338.31324768066406\n",
      "resnet_model size (MB): 101.71881866455078\n"
     ]
    }
   ],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()  # 参数数量 * 每个参数的字节数\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2  # 转换为MB\n",
    "    return size_all_mb\n",
    "\n",
    "# 比较两个模型的大小\n",
    "print(f\"swin_model size (MB): {get_model_size(swin_model)}\")\n",
    "print(f\"resnet_model size (MB): {get_model_size(resnet_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83230985-cc97-467f-871f-f04bad6ce1df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_model - FLOPs: 15.19 GMac, Params: 88.29 M\n",
      "resnet_model - FLOPs: 6.27 GMac, Params: 26.61 M\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# 比较两个模型的 FLOPs\n",
    "with torch.cuda.device(0):  # 如果有GPU可以指定使用\n",
    "    flops_a, params_a = get_model_complexity_info(swin_model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
    "    flops_b, params_b = get_model_complexity_info(resnet_model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
    "\n",
    "print(f\"swin_model - FLOPs: {flops_a}, Params: {params_a}\")\n",
    "print(f\"resnet_model - FLOPs: {flops_b}, Params: {params_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ab0b9d-dfb0-47f3-8276-045bdcb60cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_model Memory Usage (MB): 571.97314453125\n",
      "resnet_model Memory Usage (MB): 577.12939453125\n",
      "swin_model Memory Usage (MB) (256 pics): 6575.02392578125\n",
      "resnet_model Memory Usage (MB) (256 pics): 3244.02392578125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "\n",
    "def get_memory_usage(model, input_size=(1, 3, 224, 224)):\n",
    "    # 清理缓存，确保数据准确\n",
    "    torch.cuda.empty_cache()\n",
    "    input_data = torch.randn(input_size).cuda()  # 假设输入大小为 224x224 的图像\n",
    "    model = model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        _ = model(input_data)\n",
    "        max_memory = torch.cuda.max_memory_allocated() / 1024**2  # 转换为 MB\n",
    "\n",
    "    return max_memory\n",
    "\n",
    "print(f\"swin_model Memory Usage (MB): {get_memory_usage(swin_model)}\")\n",
    "print(f\"resnet_model Memory Usage (MB): {get_memory_usage(resnet_model)}\")\n",
    "\n",
    "print(f\"swin_model Memory Usage (MB) (256 pics): {get_memory_usage(swin_model, (256, 3, 224, 224))}\")\n",
    "print(f\"resnet_model Memory Usage (MB) (256 pics): {get_memory_usage(resnet_model, (256, 3, 224, 224))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49892ee8-695c-4314-ad03-db620ea03a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_model Inference Time (seconds): 0.017622420787811278\n",
      "resnet_model Inference Time (seconds): 0.006609113216400147\n",
      "swin_model Inference Time (seconds) (256 pics): 1.0379394555091859\n",
      "resnet_model Inference Time (seconds) (256 pics): 0.36501954078674315\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_inference_time(model, input_size=(1, 3, 224, 224), iterations=100):\n",
    "    input_data = torch.randn(input_size).cuda()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # 热身运行，避免初始加载影响结果\n",
    "    with torch.no_grad():\n",
    "        _ = model(input_data)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(iterations):\n",
    "            _ = model(input_data)\n",
    "    avg_inference_time = (time.time() - start_time) / iterations\n",
    "    return avg_inference_time\n",
    "\n",
    "print(f\"swin_model Inference Time (seconds): {get_inference_time(swin_model)}\")\n",
    "print(f\"resnet_model Inference Time (seconds): {get_inference_time(resnet_model)}\")\n",
    "\n",
    "print(f\"swin_model Inference Time (seconds) (256 pics): {get_inference_time(swin_model, input_size=(256, 3, 224, 224))}\")\n",
    "print(f\"resnet_model Inference Time (seconds) (256 pics): {get_inference_time(resnet_model, input_size=(256, 3, 224, 224))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c07b3-aa49-4428-bbea-391a5c6960e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorchEnv]",
   "language": "python",
   "name": "conda-env-pytorchEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
