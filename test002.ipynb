{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d2b6a0-cac2-4eeb-bc02-7a0b70baad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae81179-bab3-4f21-b5dd-c758f36649ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homec/xiaolei/anaconda3/envs/openmmlab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms as Transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.backbones.resnet_student import ResNetStudent\n",
    "from models.dis_losses.fmdv2 import AttentionProjector\n",
    "\n",
    "from data_provider.datasets.market1501 import Market1501\n",
    "from data_provider.datasets.cuhk03 import CUHK03\n",
    "from data_provider.datasets.msmt17 import MSMT17\n",
    "from data_provider.datasets.dukemtmcreid import DukeMTMCreID\n",
    "from data_provider.datasets.custom_data import CustomReid\n",
    "from data_provider.datasets import ImageDataset\n",
    "from data_provider.collate_batch import val_collate_fn\n",
    "from utils.reid_metric import R1_mAP, R1_mAP_reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fe3230-7be1-4679-a58a-6cf2cd7cf54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homec/xiaolei/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# 递归删除指定目录下的.ipynb_checkpoints文件夹\n",
    "def remove_ipynb_checkpoints(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for dir in dirs:\n",
    "            if dir == \".ipynb_checkpoints\":\n",
    "                folder_path = os.path.join(root, dir)\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"Deleted: {folder_path}\")\n",
    "\n",
    "class SwinTransformerTeacher(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(SwinTransformerTeacher, self).__init__()\n",
    "        self.model = timm.create_model('swin_base_patch4_window7_224')\n",
    "        self.num_features = num_features\n",
    "        self.feat = nn.Linear(1024, num_features) if num_features > 0 else None\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        patch_embed = self.model.patch_embed  # Patch Embedding 层\n",
    "        pos_drop = self.model.pos_drop\n",
    "        layers = self.model.layers  # 基本层（包含多个 SwinBlock）\n",
    "        \n",
    "        x = patch_embed(x)  # Patch Embedding\n",
    "        x = pos_drop(x)\n",
    "        for layer in layers:  # 逐个通过 BasicLayer\n",
    "            # x = layer(x)\n",
    "            # features.append(x)\n",
    "            for block in layer.blocks:\n",
    "                x = block(x)\n",
    "            features.append(x)\n",
    "            if layer.downsample is not None:\n",
    "                x = layer.downsample(x)\n",
    "        return tuple(features)\n",
    "\n",
    "    def forward_specific_stage(self, x, stage, down_sample=True):\n",
    "        BS, L, C = x.shape\n",
    "\n",
    "        if stage == 2:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-4].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-3].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 3:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-3].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-2].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 4:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-2].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-1].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "            norm_layer = self.model.norm\n",
    "            x = norm_layer(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "\n",
    "'''\n",
    "# 这个版本的残差网络是最基础的网络\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        features.append(stage3_out)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        features.append(stage4_out)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "'''\n",
    "'''\n",
    "# 这个版本的残差网络是修改过最大池化的网络\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        # 修改 layer1 和 layer2，向每个残差块中的 ReLU 前加上 InstanceNorm2d\n",
    "        self._modify_layer(self.model.layer1)\n",
    "        self._modify_layer(self.model.layer2)\n",
    "        self._modify_layer_stride(self.model.layer4[0].conv2, self.model.layer4[0].downsample[0])\n",
    "        # 输出设置\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        features.append(stage3_out)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        features.append(stage4_out)\n",
    "        return tuple(features)\n",
    "\n",
    "    def _modify_layer(self, layer):\n",
    "        \"\"\"\n",
    "        在每个残差块中的 ReLU 前加上 InstanceNorm2d 操作。\n",
    "        \"\"\"\n",
    "        for block in layer:\n",
    "            # 修改 conv1 和 conv2 之后的 ReLU，将 InstanceNorm2d 放在 ReLU 前面\n",
    "            # 对于每个残差块，将 InstanceNorm2d 加入到 ReLU 之前\n",
    "            block.act3 = nn.Sequential(\n",
    "                nn.InstanceNorm2d(block.conv3.out_channels, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def _modify_layer_stride(self, last_layer, last_layer_downsample):\n",
    "        # 在最后一层将stride改为1\n",
    "        last_layer.stride = (1, 1)\n",
    "        last_layer_downsample.stride = (1, 1)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 这个残差网络是提取每个残差块特征的网络\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        # 修改 layer1 和 layer2，向每个残差块中的 ReLU 前加上 InstanceNorm2d\n",
    "        self._modify_layer(self.model.layer1)\n",
    "        self._modify_layer(self.model.layer2)\n",
    "        self._modify_layer_stride(self.model.layer4[0].conv2, self.model.layer4[0].downsample[0])\n",
    "        # 进行特征映射\n",
    "        self.projector_1 = AttentionProjector(student_dims=256, teacher_dims=128, hw_dims=(56, 56), pos_dims=128, window_shapes=(1, 1), self_query=True, \n",
    "                                 softmax_scale=5.0, num_heads=4)\n",
    "        self.projector_2 = AttentionProjector(student_dims=512, teacher_dims=256, hw_dims=(28, 28), pos_dims=256, window_shapes=(1, 1), self_query=True, \n",
    "                                         softmax_scale=5.0, num_heads=8)\n",
    "        self.projector_3 = AttentionProjector(student_dims=1024, teacher_dims=512, hw_dims=(14, 14), pos_dims=512, window_shapes=(1, 1), self_query=True, \n",
    "                                         softmax_scale=5.0, num_heads=16)\n",
    "        self.projector_4 = AttentionProjector(student_dims=2048, teacher_dims=1024, hw_dims=(7, 7), pos_dims=1024, window_shapes=(1, 1), self_query=True, \n",
    "                                 softmax_scale=5.0, num_heads=32)\n",
    "        # 输出设置\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        # features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        # features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        student_feature_proj3 = self.projector_3(stage3_out)\n",
    "        features.append(student_feature_proj3)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        student_feature_proj4 = self.projector_4(stage4_out)\n",
    "        features.append(student_feature_proj4)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def extract_feat_proj(self, x):\n",
    "        features = []\n",
    "        student_features = self.extract_feat(x)\n",
    "        # student_feature_proj1 = self.projector_1(student_features[0])\n",
    "        # features.append(student_feature_proj1)\n",
    "        # student_feature_proj2 = self.projector_2(student_features[1])\n",
    "        # features.append(student_feature_proj2)\n",
    "        student_feature_proj3 = self.projector_3(student_features[2])\n",
    "        features.append(student_feature_proj3)\n",
    "        student_feature_proj4 = self.projector_4(student_features[3])\n",
    "        features.append(student_feature_proj4)\n",
    "        return tuple(features)\n",
    "        \n",
    "    def _modify_layer(self, layer):\n",
    "        \"\"\"\n",
    "        在每个残差块中的 ReLU 前加上 InstanceNorm2d 操作。\n",
    "        \"\"\"\n",
    "        for block in layer:\n",
    "            # 修改 conv1 和 conv2 之后的 ReLU，将 InstanceNorm2d 放在 ReLU 前面\n",
    "            # 对于每个残差块，将 InstanceNorm2d 加入到 ReLU 之前\n",
    "            block.act3 = nn.Sequential(\n",
    "                nn.InstanceNorm2d(block.conv3.out_channels, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def _modify_layer_stride(self, last_layer, last_layer_downsample):\n",
    "        # 在最后一层将stride改为1\n",
    "        last_layer.stride = (1, 1)\n",
    "        last_layer_downsample.stride = (1, 1)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "'''\n",
    "\n",
    "class Data_Processor(object):\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transformer = Transforms.Compose([\n",
    "            Transforms.Resize((self.height, self.width)),\n",
    "            Transforms.ToTensor(),\n",
    "            Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.transformer(img).unsqueeze(0)\n",
    "\n",
    "data_processor = Data_Processor(height=224, width=224)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# swin_model = SwinTransformerTeacher(num_features=512).cuda()\n",
    "# swin_model.eval()\n",
    "\n",
    "# resnet_model = ResNetStudent(num_features=512).cuda()\n",
    "# resnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393de679-4502-4a53-834b-9c5627b93bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetStudent(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): Sequential(\n",
       "          (0): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (feat): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# swin_transformer\n",
    "swin_model = SwinTransformerTeacher(num_features=512).cuda()\n",
    "swin_model.eval()\n",
    "\n",
    "swin_weight_path = '/homec/xiaolei/projects/ISR/weights/swin_base_patch4_window7_224.pth'\n",
    "swin_weight = torch.load(swin_weight_path)\n",
    "swin_model.load_state_dict(swin_weight['state_dict'], strict=True)\n",
    "\n",
    "# 残差网络\n",
    "# 初始化网络\n",
    "resnet_model = ResNetStudent(num_features=512).cuda()\n",
    "resnet_model.eval()\n",
    "# 加载预训练权重\n",
    "resnet_weight_path = 'weights/student_model_base5_strong_reid_mmd_mse_loss_confusion/best_student_model.pth'\n",
    "resnet_weight = torch.load(resnet_weight_path)\n",
    "resnet_model.load_state_dict(resnet_weight, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7688511-b180-4fda-8bd9-c9aa294175ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/147_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/results.txt\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/.ipynb_checkpoints\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/148_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/202_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/203_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/236_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/302_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/303_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/438_1129\n",
      "sub_img_root: /homec/xiaolei/projects/ultralytics/runs/results11/439_1129\n",
      "avg_simlarity: 0.8889502882957458\n"
     ]
    }
   ],
   "source": [
    "img_root = \"/homec/xiaolei/projects/ultralytics/runs/results11\"\n",
    "\n",
    "all_simlarity = 0\n",
    "img_file_count = 0\n",
    "for item in os.listdir(img_root):\n",
    "    sub_img_root = os.path.join(img_root, item)\n",
    "    print(f'sub_img_root: {sub_img_root}')\n",
    "    \n",
    "    # 判断是否是文件夹\n",
    "    if os.path.isdir(sub_img_root):\n",
    "        img_files = glob.glob(os.path.join(sub_img_root, '*.jpg'))\n",
    "        img_file_count += len(img_files)\n",
    "        for img_file in img_files:\n",
    "            query = data_processor(Image.open(img_file).convert('RGB')).cuda()\n",
    "            with torch.no_grad():\n",
    "                A_feat = F.normalize(swin_model(query), dim=1).cpu()\n",
    "                B_feat = F.normalize(resnet_model(query), dim=1).cpu()\n",
    "            # print(A_feat)\n",
    "            simlarity = A_feat.matmul(B_feat.transpose(1, 0))\n",
    "            # print(f'simlarity: {simlarity[0, 0]}')\n",
    "            all_simlarity += simlarity[0, 0]\n",
    "    # break\n",
    "\n",
    "print(f'avg_simlarity: {all_simlarity / img_file_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91271cf5-6993-4e2d-a67d-a7f0debd764a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试自定义数据集\n",
    "def make_val_data_loader():\n",
    "    val_transforms = Transforms.Compose([\n",
    "        Transforms.Resize((224, 224)),\n",
    "        Transforms.ToTensor(),\n",
    "        Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = CustomReid(dataset_dir='court1888')\n",
    "    val_set = ImageDataset(dataset.query + dataset.gallery, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=128, shuffle=False, num_workers=8,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "    return val_loader, len(dataset.query)\n",
    "\n",
    "val_loader, num_query = make_val_data_loader()\n",
    "\n",
    "evaluator_resnet = R1_mAP_reranking(num_query)\n",
    "evaluator_swin = R1_mAP_reranking(num_query)\n",
    "evaluator_resnet.reset()\n",
    "evaluator_swin.reset()\n",
    "with tqdm(total=len(val_loader), desc=f\"valid\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for person_image_bs in val_loader:\n",
    "            output_resnet = []\n",
    "            output_swim = []\n",
    "            data, pids, camids = person_image_bs\n",
    "            data = data.to(device) if torch.cuda.device_count() >= 1 else data\n",
    "            feat_resnet = resnet_model(data)\n",
    "            feat_swin = swin_model(data)\n",
    "            output_resnet.append(feat_resnet)\n",
    "            output_resnet.append(pids)\n",
    "            output_resnet.append(camids)\n",
    "            output_resnet = tuple(output_resnet)\n",
    "            output_swim.append(feat_swin)\n",
    "            output_swim.append(pids)\n",
    "            output_swim.append(camids)\n",
    "            output_swim = tuple(output_swim)\n",
    "            evaluator_resnet.update(output_resnet)\n",
    "            evaluator_swin.update(output_swim)\n",
    "            pbar.update(1)\n",
    "cmc_resnet, mAP_resnet = evaluator_resnet.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_resnet: {:.1%}\".format(mAP_resnet))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_resnet curve, Rank-{:<3}:{:.1%}\".format(r, cmc_resnet[r - 1]))\n",
    "cmc_swin, mAP_swin = evaluator_swin.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_swin: {:.1%}\".format(mAP_swin))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_swin curve, Rank-{:<3}:{:.1%}\".format(r, cmc_swin[r - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7539aa6-03fb-4a54-8620-aa28f4cf3679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集Market1501\n",
    "def make_val_data_loader():\n",
    "    val_transforms = Transforms.Compose([\n",
    "        Transforms.Resize((224, 224)),\n",
    "        Transforms.ToTensor(),\n",
    "        Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = Market1501()\n",
    "    val_set = ImageDataset(dataset.query + dataset.gallery, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=128, shuffle=False, num_workers=8,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "    return val_loader, len(dataset.query)\n",
    "\n",
    "val_loader, num_query = make_val_data_loader()\n",
    "\n",
    "evaluator_resnet = R1_mAP_reranking(num_query)\n",
    "evaluator_swin = R1_mAP_reranking(num_query)\n",
    "evaluator_resnet.reset()\n",
    "evaluator_swin.reset()\n",
    "with tqdm(total=len(val_loader), desc=f\"valid\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for person_image_bs in val_loader:\n",
    "            output_resnet = []\n",
    "            output_swim = []\n",
    "            data, pids, camids = person_image_bs\n",
    "            data = data.to(device) if torch.cuda.device_count() >= 1 else data\n",
    "            feat_resnet = resnet_model(data)\n",
    "            feat_swin = swin_model(data)\n",
    "            output_resnet.append(feat_resnet)\n",
    "            output_resnet.append(pids)\n",
    "            output_resnet.append(camids)\n",
    "            output_resnet = tuple(output_resnet)\n",
    "            output_swim.append(feat_swin)\n",
    "            output_swim.append(pids)\n",
    "            output_swim.append(camids)\n",
    "            output_swim = tuple(output_swim)\n",
    "            evaluator_resnet.update(output_resnet)\n",
    "            evaluator_swin.update(output_swim)\n",
    "            pbar.update(1)\n",
    "cmc_resnet, mAP_resnet = evaluator_resnet.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_resnet: {:.1%}\".format(mAP_resnet))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_resnet curve, Rank-{:<3}:{:.1%}\".format(r, cmc_resnet[r - 1]))\n",
    "cmc_swin, mAP_swin = evaluator_swin.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_swin: {:.1%}\".format(mAP_swin))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_swin curve, Rank-{:<3}:{:.1%}\".format(r, cmc_swin[r - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb5344-3b4b-4160-ba1f-546cbac1cf24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集MSMT17\n",
    "def make_val_data_loader():\n",
    "    val_transforms = Transforms.Compose([\n",
    "        Transforms.Resize((224, 224)),\n",
    "        Transforms.ToTensor(),\n",
    "        Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = MSMT17()\n",
    "    val_set = ImageDataset(dataset.query + dataset.gallery, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=128, shuffle=False, num_workers=8,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "    return val_loader, len(dataset.query)\n",
    "\n",
    "val_loader, num_query = make_val_data_loader()\n",
    "\n",
    "evaluator_resnet = R1_mAP_reranking(num_query)\n",
    "evaluator_swin = R1_mAP_reranking(num_query)\n",
    "evaluator_resnet.reset()\n",
    "evaluator_swin.reset()\n",
    "with tqdm(total=len(val_loader), desc=f\"valid\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for person_image_bs in val_loader:\n",
    "            output_resnet = []\n",
    "            output_swim = []\n",
    "            data, pids, camids = person_image_bs\n",
    "            data = data.to(device) if torch.cuda.device_count() >= 1 else data\n",
    "            feat_resnet = resnet_model(data)\n",
    "            feat_swin = swin_model(data)\n",
    "            output_resnet.append(feat_resnet)\n",
    "            output_resnet.append(pids)\n",
    "            output_resnet.append(camids)\n",
    "            output_resnet = tuple(output_resnet)\n",
    "            output_swim.append(feat_swin)\n",
    "            output_swim.append(pids)\n",
    "            output_swim.append(camids)\n",
    "            output_swim = tuple(output_swim)\n",
    "            evaluator_resnet.update(output_resnet)\n",
    "            evaluator_swin.update(output_swim)\n",
    "            pbar.update(1)\n",
    "cmc_resnet, mAP_resnet = evaluator_resnet.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_resnet: {:.1%}\".format(mAP_resnet))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_resnet curve, Rank-{:<3}:{:.1%}\".format(r, cmc_resnet[r - 1]))\n",
    "cmc_swin, mAP_swin = evaluator_swin.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_swin: {:.1%}\".format(mAP_swin))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_swin curve, Rank-{:<3}:{:.1%}\".format(r, cmc_swin[r - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b045aed-fb9e-4640-b4ec-ff744a1419f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集CUHK03\n",
    "def make_val_data_loader():\n",
    "    val_transforms = Transforms.Compose([\n",
    "        Transforms.Resize((224, 224)),\n",
    "        Transforms.ToTensor(),\n",
    "        Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = CUHK03()\n",
    "    val_set = ImageDataset(dataset.query + dataset.gallery, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=128, shuffle=False, num_workers=8,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "    return val_loader, len(dataset.query)\n",
    "\n",
    "val_loader, num_query = make_val_data_loader()\n",
    "\n",
    "evaluator_resnet = R1_mAP_reranking(num_query)\n",
    "evaluator_swin = R1_mAP_reranking(num_query)\n",
    "evaluator_resnet.reset()\n",
    "evaluator_swin.reset()\n",
    "with tqdm(total=len(val_loader), desc=f\"valid\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for person_image_bs in val_loader:\n",
    "            output_resnet = []\n",
    "            output_swim = []\n",
    "            data, pids, camids = person_image_bs\n",
    "            data = data.to(device) if torch.cuda.device_count() >= 1 else data\n",
    "            feat_resnet = resnet_model(data)\n",
    "            feat_swin = swin_model(data)\n",
    "            output_resnet.append(feat_resnet)\n",
    "            output_resnet.append(pids)\n",
    "            output_resnet.append(camids)\n",
    "            output_resnet = tuple(output_resnet)\n",
    "            output_swim.append(feat_swin)\n",
    "            output_swim.append(pids)\n",
    "            output_swim.append(camids)\n",
    "            output_swim = tuple(output_swim)\n",
    "            evaluator_resnet.update(output_resnet)\n",
    "            evaluator_swin.update(output_swim)\n",
    "            pbar.update(1)\n",
    "cmc_resnet, mAP_resnet = evaluator_resnet.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_resnet: {:.1%}\".format(mAP_resnet))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_resnet curve, Rank-{:<3}:{:.1%}\".format(r, cmc_resnet[r - 1]))\n",
    "cmc_swin, mAP_swin = evaluator_swin.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_swin: {:.1%}\".format(mAP_swin))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_swin curve, Rank-{:<3}:{:.1%}\".format(r, cmc_swin[r - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc67c8d-1bdc-40ec-ae47-32885934aa44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集DukeMTMCreID\n",
    "def make_val_data_loader():\n",
    "    val_transforms = Transforms.Compose([\n",
    "        Transforms.Resize((224, 224)),\n",
    "        Transforms.ToTensor(),\n",
    "        Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = DukeMTMCreID()\n",
    "    val_set = ImageDataset(dataset.query + dataset.gallery, val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=128, shuffle=False, num_workers=8,\n",
    "        collate_fn=val_collate_fn\n",
    "    )\n",
    "    return val_loader, len(dataset.query)\n",
    "\n",
    "val_loader, num_query = make_val_data_loader()\n",
    "\n",
    "evaluator_resnet = R1_mAP_reranking(num_query)\n",
    "evaluator_swin = R1_mAP_reranking(num_query)\n",
    "evaluator_resnet.reset()\n",
    "evaluator_swin.reset()\n",
    "with tqdm(total=len(val_loader), desc=f\"valid\") as pbar:\n",
    "    with torch.no_grad():\n",
    "        for person_image_bs in val_loader:\n",
    "            output_resnet = []\n",
    "            output_swim = []\n",
    "            data, pids, camids = person_image_bs\n",
    "            data = data.to(device) if torch.cuda.device_count() >= 1 else data\n",
    "            feat_resnet = resnet_model(data)\n",
    "            feat_swin = swin_model(data)\n",
    "            output_resnet.append(feat_resnet)\n",
    "            output_resnet.append(pids)\n",
    "            output_resnet.append(camids)\n",
    "            output_resnet = tuple(output_resnet)\n",
    "            output_swim.append(feat_swin)\n",
    "            output_swim.append(pids)\n",
    "            output_swim.append(camids)\n",
    "            output_swim = tuple(output_swim)\n",
    "            evaluator_resnet.update(output_resnet)\n",
    "            evaluator_swin.update(output_swim)\n",
    "            pbar.update(1)\n",
    "cmc_resnet, mAP_resnet = evaluator_resnet.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_resnet: {:.1%}\".format(mAP_resnet))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_resnet curve, Rank-{:<3}:{:.1%}\".format(r, cmc_resnet[r - 1]))\n",
    "cmc_swin, mAP_swin = evaluator_swin.compute()\n",
    "print('Validation Results')\n",
    "print(\"mAP_swin: {:.1%}\".format(mAP_swin))\n",
    "for r in [1, 5, 10]:\n",
    "    print(\"CMC_swin curve, Rank-{:<3}:{:.1%}\".format(r, cmc_swin[r - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431b6af-4ceb-4b14-8be5-9803afdab7df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "swin_model = SwinTransformerTeacher()\n",
    "swin_model = swin_model.to(device)\n",
    "res_model = ResNetStudent()\n",
    "res_model = res_model.to(device)\n",
    "\n",
    "swin_features = swin_model.extract_feat(torch.randn(1, 3, 224, 224).to(device))\n",
    "res_features = res_model.extract_feat(torch.randn(1, 3, 224, 224).to(device))\n",
    "\n",
    "for swin_feature in swin_features:\n",
    "    print(swin_feature.shape)\n",
    "print('='*100)\n",
    "for res_feature in res_features:\n",
    "    print(res_feature.shape)\n",
    "\n",
    "print(res_model(torch.randn(1, 3, 224, 224).to(device)).shape)\n",
    "print(swin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8629956-44cf-417d-a43c-5087223bde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def MMD(x, y, kernel):\n",
    "    \"\"\"Emprical maximum mean discrepancy. The lower the result\n",
    "       the more evidence that distributions are the same.\n",
    "\n",
    "    Args:\n",
    "        x: first sample, distribution P\n",
    "        y: second sample, distribution Q\n",
    "        kernel: kernel type such as \"multiscale\" or \"rbf\"\n",
    "    \"\"\"\n",
    "    xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "    \n",
    "    dxx = rx.t() + rx - 2. * xx # Used for A in (1)\n",
    "    dyy = ry.t() + ry - 2. * yy # Used for B in (1)\n",
    "    dxy = rx.t() + ry - 2. * zz # Used for C in (1)\n",
    "    \n",
    "    XX, YY, XY = (torch.zeros(xx.shape),\n",
    "                  torch.zeros(xx.shape),\n",
    "                  torch.zeros(xx.shape))\n",
    "    \n",
    "    if kernel == \"multiscale\":\n",
    "        \n",
    "        bandwidth_range = [0.2, 0.5, 0.9, 1.3]\n",
    "        for a in bandwidth_range:\n",
    "            XX += a**2 * (a**2 + dxx)**-1\n",
    "            YY += a**2 * (a**2 + dyy)**-1\n",
    "            XY += a**2 * (a**2 + dxy)**-1\n",
    "            \n",
    "    if kernel == \"rbf\":\n",
    "      \n",
    "        bandwidth_range = [10, 15, 20, 50]\n",
    "        for a in bandwidth_range:\n",
    "            XX += torch.exp(-0.5*dxx/a)\n",
    "            YY += torch.exp(-0.5*dyy/a)\n",
    "            XY += torch.exp(-0.5*dxy/a)\n",
    "      \n",
    "      \n",
    "\n",
    "    return torch.mean(XX + YY - 2. * XY)\n",
    "\n",
    "class RBF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_kernels=5, mul_factor=2.0, bandwidth=None):\n",
    "        super().__init__()\n",
    "        self.bandwidth_multipliers = mul_factor ** (torch.arange(n_kernels) - n_kernels // 2)\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def get_bandwidth(self, L2_distances):\n",
    "        if self.bandwidth is None:\n",
    "            n_samples = L2_distances.shape[0]\n",
    "            return L2_distances.data.sum() / (n_samples ** 2 - n_samples)\n",
    "\n",
    "        return self.bandwidth\n",
    "\n",
    "    def forward(self, X):\n",
    "        L2_distances = torch.cdist(X, X) ** 2\n",
    "        return torch.exp(-L2_distances[None, ...] / (self.get_bandwidth(L2_distances) * self.bandwidth_multipliers)[:, None, None]).sum(dim=0)\n",
    "\n",
    "\n",
    "class MMDLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel=RBF()):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        K = self.kernel(torch.vstack([X, Y]))\n",
    "\n",
    "        X_size = X.shape[0]\n",
    "        XX = K[:X_size, :X_size].mean()\n",
    "        XY = K[:X_size, X_size:].mean()\n",
    "        YY = K[X_size:, X_size:].mean()\n",
    "        return XX - 2 * XY + YY\n",
    "\n",
    "def rbf_kernel(x, y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    计算高斯 RBF 核函数\n",
    "    :param x: 输入张量 x (batch_size, feature_dim)\n",
    "    :param y: 输入张量 y (batch_size, feature_dim)\n",
    "    :param sigma: 核函数的宽度，控制相似度的范围\n",
    "    :return: 计算得到的 RBF 核\n",
    "    \"\"\"\n",
    "    # 计算样本之间的平方欧几里得距离\n",
    "    xx = torch.sum(x ** 2, dim=1, keepdim=True)\n",
    "    yy = torch.sum(y ** 2, dim=1, keepdim=True)\n",
    "    dist = xx + yy.t() - 2 * torch.matmul(x, y.t())\n",
    "    \n",
    "    # 计算 RBF 核（高斯核）\n",
    "    return torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "def mmd_loss(X, Y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    计算最大均值差异（MMD）损失\n",
    "    :param X: 样本集 X (batch_size_1, feature_dim)\n",
    "    :param Y: 样本集 Y (batch_size_2, feature_dim)\n",
    "    :param sigma: 核函数的宽度，控制相似度的范围\n",
    "    :return: MMD 损失\n",
    "    \"\"\"\n",
    "    # 计算 RBF 核\n",
    "    XX = rbf_kernel(X, X, sigma)  # X 中样本对之间的核\n",
    "    YY = rbf_kernel(Y, Y, sigma)  # Y 中样本对之间的核\n",
    "    XY = rbf_kernel(X, Y, sigma)  # X 和 Y 中样本对之间的核\n",
    "\n",
    "    # 计算 MMD 损失\n",
    "    loss = XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 示例：定义一些随机的样本数据\n",
    "X = torch.randn(100, 128)  # 样本集 X，假设有 100 个样本，每个样本是 128 维特征\n",
    "Y = torch.randn(100, 128)  # 样本集 Y，假设有 100 个样本，每个样本是 128 维特征\n",
    "\n",
    "# 计算 MMD 损失\n",
    "loss = mmd_loss(X, Y, sigma=1.0)\n",
    "MMDLoss = MMDLoss()\n",
    "res = MMDLoss(X, Y)\n",
    "res2 = MMD(X, Y, kernel=\"rbf\")\n",
    "print(f\"MMD Loss: {loss.item()}\")\n",
    "print(f\"MMD Loss: {res.item()}\")\n",
    "print(f\"MMD Loss: {res2.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001d754-0383-40ac-8b87-cf9027aea0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path of your image pair\n",
    "image_pair_path = ['test_data/reid/19-24-16_0_2*2.jpg',\n",
    "           'test_data/reid/19-24-19_0_1*2.jpg']\n",
    "\n",
    "query_A = data_processor(Image.open(image_pair_path[0]).convert('RGB')).cuda()\n",
    "query_B = data_processor(Image.open(image_pair_path[1]).convert('RGB')).cuda()\n",
    "with torch.no_grad():\n",
    "    A_feat = F.normalize(model(query_A), dim=1).cpu()\n",
    "    B_feat = F.normalize(model(query_B), dim=1).cpu()\n",
    "simlarity = A_feat.matmul(B_feat.transpose(1, 0))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (2 * 2, 2))\n",
    "image1 = np.array(Image.open(image_pair_path[0]).convert('RGB').resize((64, 128)))\n",
    "image2 = np.array(Image.open(image_pair_path[1]).convert('RGB').resize((64, 128)))\n",
    "\n",
    "axes[0].imshow(image1)\n",
    "axes[0].set_title('image 1', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(image2)\n",
    "axes[1].set_title('image 2', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "print(\"\\033[1;31m The similarity is {}\".format(simlarity[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c77cd-6241-4318-9ba9-e737d95d5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path of your image pair\n",
    "image_pair_path = ['test_data/reid/18-48-00_0_1*1.jpg',\n",
    "           'test_data/reid/19-24-19_0_1*2.jpg']\n",
    "\n",
    "query_A = data_processor(Image.open(image_pair_path[0]).convert('RGB')).cuda()\n",
    "query_B = data_processor(Image.open(image_pair_path[1]).convert('RGB')).cuda()\n",
    "with torch.no_grad():\n",
    "    A_feat = F.normalize(model(query_A), dim=1).cpu()\n",
    "    B_feat = F.normalize(model(query_B), dim=1).cpu()\n",
    "simlarity = A_feat.matmul(B_feat.transpose(1, 0))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (2 * 2, 2))\n",
    "image1 = np.array(Image.open(image_pair_path[0]).convert('RGB').resize((64, 128)))\n",
    "image2 = np.array(Image.open(image_pair_path[1]).convert('RGB').resize((64, 128)))\n",
    "\n",
    "axes[0].imshow(image1)\n",
    "axes[0].set_title('image 1', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(image2)\n",
    "axes[1].set_title('image 2', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "print(\"\\033[1;31m The similarity is {}\".format(simlarity[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580d373-b5ba-4688-84f2-6bfe21f642cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = SwinTransformerTeacher(num_features=512).cuda()\n",
    "model.eval()\n",
    "\n",
    "model_b = ResNetStudent(num_features=512).cuda()\n",
    "model.eval()\n",
    "\n",
    "# swin_transformer\n",
    "weight_path = '/homec/xiaolei/projects/ISR/weights/swin_base_patch4_window7_224.pth'\n",
    "weight = torch.load(weight_path)\n",
    "model_a.load_state_dict(weight['state_dict'], strict=True)\n",
    "\n",
    "# 残差网络\n",
    "weight_path = 'weights/student_model_base5_strong_reid_mmd_mse_loss/best_student_model.pth'\n",
    "weight = torch.load(weight_path)\n",
    "model_b.load_state_dict(weight, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d39b1-8803-4913-b6b4-52e080a5b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()  # 参数数量 * 每个参数的字节数\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2  # 转换为MB\n",
    "    return size_all_mb\n",
    "\n",
    "# 比较两个模型的大小\n",
    "print(f\"Model A size (MB): {get_model_size(model_a)}\")\n",
    "print(f\"Model B size (MB): {get_model_size(model_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd36e1-d960-4940-9a5f-49c4882f6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# 比较两个模型的 FLOPs\n",
    "with torch.cuda.device(0):  # 如果有GPU可以指定使用\n",
    "    flops_a, params_a = get_model_complexity_info(model_a, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
    "    flops_b, params_b = get_model_complexity_info(model_b, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
    "\n",
    "print(f\"Model A - FLOPs: {flops_a}, Params: {params_a}\")\n",
    "print(f\"Model B - FLOPs: {flops_b}, Params: {params_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188e1ea-3852-471d-994f-cc00818ad2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "\n",
    "def get_memory_usage(model, input_size=(1, 3, 224, 224)):\n",
    "    # 清理缓存，确保数据准确\n",
    "    torch.cuda.empty_cache()\n",
    "    input_data = torch.randn(input_size).cuda()  # 假设输入大小为 224x224 的图像\n",
    "    model = model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        _ = model(input_data)\n",
    "        max_memory = torch.cuda.max_memory_allocated() / 1024**2  # 转换为 MB\n",
    "\n",
    "    return max_memory\n",
    "\n",
    "print(f\"Model A Memory Usage (MB): {get_memory_usage(model_a)}\")\n",
    "print(f\"Model B Memory Usage (MB): {get_memory_usage(model_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abdca5-2c8d-43e1-9157-00ee4a4594b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_inference_time(model, input_size=(1, 3, 224, 224), iterations=100):\n",
    "    input_data = torch.randn(input_size).cuda()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # 热身运行，避免初始加载影响结果\n",
    "    with torch.no_grad():\n",
    "        _ = model(input_data)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(iterations):\n",
    "            _ = model(input_data)\n",
    "    avg_inference_time = (time.time() - start_time) / iterations\n",
    "    return avg_inference_time\n",
    "\n",
    "print(f\"Model A Inference Time (seconds): {get_inference_time(model_a)}\")\n",
    "print(f\"Model B Inference Time (seconds): {get_inference_time(model_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a0cdd-23b1-48f5-81c6-c4d410d81069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)  # 使用 json.load() 将 JSON 文件加载为 Python 对象\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件 {file_path} 未找到\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON 文件解析错误: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {e}\")\n",
    "\n",
    "def modify_path(original_path):\n",
    "    # 替换路径的根目录，同时将反斜杠替换为正斜杠\n",
    "    modified_path = original_path.replace(\"\\\\\", \"/\").replace(\"./data\", \"./test_data\")\n",
    "    return modified_path\n",
    "\n",
    "def save_to_json(data, file_path):\n",
    "    try:\n",
    "        # 使用 json.dump 将数据保存到文件\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)  # 格式化输出并支持非 ASCII 字符\n",
    "            print(f\"数据已成功保存到 {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存数据时发生错误: {e}\")\n",
    "\n",
    "# 示例用法\n",
    "file_path = \"test_data/cuhk03/splits_new_labeled.json\"  # 替换为你的 JSON 文件路径\n",
    "output_file_path = \"test_data/cuhk03/splits_new_labeled2.json\"  # 替换为你的 JSON 文件路径\n",
    "json_data = read_json(file_path)\n",
    "\n",
    "if json_data:\n",
    "    print(\"读取到的 JSON 数据：\")\n",
    "    for i in range(len(json_data)):\n",
    "        for key in ('train', 'query', 'gallery'):\n",
    "            for j in range(len(json_data[i][key])):\n",
    "                json_data[i][key][j][0] = modify_path(json_data[i][key][j][0])\n",
    "    save_to_json(json_data, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30982fe5-ebd0-40a7-badf-812803dd5000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files(src_folder, dest_folder):\n",
    "    # 检查源文件夹是否存在\n",
    "    if not os.path.exists(src_folder):\n",
    "        print(f\"源文件夹 {src_folder} 不存在\")\n",
    "        return\n",
    "\n",
    "    # 如果目标文件夹不存在，则创建\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    # 遍历源文件夹中的所有文件\n",
    "    for file_name in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, file_name)\n",
    "        dest_file = os.path.join(dest_folder, file_name)\n",
    "\n",
    "        # 如果是文件则进行复制\n",
    "        if os.path.isfile(src_file):\n",
    "            shutil.copy2(src_file, dest_file)  # 使用 copy2 保留文件的元数据\n",
    "            # print(f\"已复制: {src_file} 到 {dest_file}\")\n",
    "        else:\n",
    "            print(f\"跳过非文件: {src_file}\")\n",
    "\n",
    "# 示例用法\n",
    "src_folder = \"datasets/valid\"\n",
    "dest_folder = \"datasets/basketball_player_fusion/valid\"\n",
    "copy_files(src_folder, dest_folder)\n",
    "print(f'复制完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b28a3-5391-464c-a5b4-a36679206c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(source_dir, target_dir, train_ratio=0.8):\n",
    "    # 获取源文件夹中所有文件\n",
    "    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "    \n",
    "    # 按照 train_ratio 划分训练集和验证集\n",
    "    train_files, val_files = train_test_split(files, test_size=1-train_ratio, random_state=42)\n",
    "    \n",
    "    # 定义训练集和验证集的目标路径\n",
    "    train_dir = os.path.join(target_dir, \"train\")\n",
    "    val_dir = os.path.join(target_dir, \"valid\")\n",
    "    \n",
    "    # 创建目标文件夹\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    # 将文件复制到训练集和验证集文件夹\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(train_dir, file))\n",
    "    \n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(val_dir, file))\n",
    "    \n",
    "    print(f\"训练集文件数量: {len(train_files)}\")\n",
    "    print(f\"验证集文件数量: {len(val_files)}\")\n",
    "    print(f\"数据集已成功分配到 {target_dir}\")\n",
    "\n",
    "# 使用示例\n",
    "source_dir = \"test_data/MSMT17/bounding_box_train\"  # 源文件夹路径\n",
    "target_dir = \"datasets/basketball_player_fusion\"  # 目标文件夹路径\n",
    "split_dataset(source_dir, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4936aa0-2408-4bf4-9772-bd05273bc034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openmmlab]",
   "language": "python",
   "name": "conda-env-openmmlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
