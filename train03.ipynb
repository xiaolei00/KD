{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c0070-ef3c-4413-84e3-3656b1c7f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379af15d-5ca0-4eeb-bf93-e25e10d90366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms as Transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import time\n",
    "from data_provider.data_factory import data_provider\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import get_config\n",
    "from optimizer import build_optimizer\n",
    "from lr_scheduler import build_scheduler\n",
    "\n",
    "from models.dis_losses import KDLoss, FreqMaskingDistillLossv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db5e81-bce1-4abc-bfd6-749a386c8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    # 检查目录是否存在\n",
    "    if not os.path.exists(directory):\n",
    "        # 如果目录不存在，则创建目录\n",
    "        os.makedirs(directory)\n",
    "        print(\"目录 '{}' 创建成功\".format(directory))\n",
    "    else:\n",
    "        print(\"目录 '{}' 已经存在\".format(directory))\n",
    "\n",
    "# 递归删除指定目录下的.ipynb_checkpoints文件夹\n",
    "def remove_ipynb_checkpoints(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for dir in dirs:\n",
    "            if dir == \".ipynb_checkpoints\":\n",
    "                folder_path = os.path.join(root, dir)\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"Deleted: {folder_path}\")\n",
    "\n",
    "class SwinTransformerTeacher(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(SwinTransformerTeacher, self).__init__()\n",
    "        self.model = timm.create_model('swin_base_patch4_window7_224')\n",
    "        self.num_features = num_features\n",
    "        self.feat = nn.Linear(1024, num_features) if num_features > 0 else None\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        patch_embed = self.model.patch_embed  # Patch Embedding 层\n",
    "        pos_drop = self.model.pos_drop\n",
    "        layers = self.model.layers  # 基本层（包含多个 SwinBlock）\n",
    "        \n",
    "        x = patch_embed(x)  # Patch Embedding\n",
    "        x = pos_drop(x)\n",
    "        for layer in layers:  # 逐个通过 BasicLayer\n",
    "            # x = layer(x)\n",
    "            # features.append(x)\n",
    "            for block in layer.blocks:\n",
    "                x = block(x)\n",
    "            features.append(x)\n",
    "            if layer.downsample is not None:\n",
    "                x = layer.downsample(x)\n",
    "        return tuple(features)\n",
    "\n",
    "    def forward_specific_stage(self, x, stage, down_sample=True):\n",
    "        BS, L, C = x.shape\n",
    "\n",
    "        if stage == 2:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-4].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-3].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 3:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-3].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-2].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "        if stage == 4:\n",
    "            if down_sample:\n",
    "                x = self.model.layers[-2].downsample(x)\n",
    "\n",
    "            for block in self.model.layers[-1].blocks:\n",
    "                x = block(x)\n",
    "\n",
    "            norm_layer = self.model.norm\n",
    "            x = norm_layer(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "\n",
    "class ResNetStudent(nn.Module):\n",
    "    def __init__(self, num_features=512):\n",
    "        super(ResNetStudent, self).__init__()\n",
    "        self.model = timm.create_model('resnet50', pretrained=True)  # 使用ResNet-50作为学生模型\n",
    "        # 修改 layer1 和 layer2，向每个残差块中的 ReLU 前加上 InstanceNorm2d\n",
    "        self._modify_layer(self.model.layer1)\n",
    "        self._modify_layer(self.model.layer2)\n",
    "        self._modify_layer_stride(self.model.layer4[0].conv2, self.model.layer4[0].downsample[0])\n",
    "        # 输出设置\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten_dim = 2048\n",
    "        self.feat = nn.Linear(self.flatten_dim, num_features) if num_features > 0 else None\n",
    "    \n",
    "    def extract_feat(self, x):\n",
    "        # 创建一个空列表，用于保存各层的输出特征\n",
    "        features = []\n",
    "        \n",
    "        # 提取每个阶段的层\n",
    "        conv1 = self.model.conv1  # 初始卷积层\n",
    "        bn1 = self.model.bn1\n",
    "        act1 = self.model.act1\n",
    "        maxpool = self.model.maxpool\n",
    "        layer1 = self.model.layer1  # 第一阶段（残差块1）\n",
    "        layer2 = self.model.layer2  # 第二阶段（残差块2）\n",
    "        layer3 = self.model.layer3  # 第三阶段（残差块3）\n",
    "        layer4 = self.model.layer4  # 第四阶段（残差块4）\n",
    "        \n",
    "        x = conv1(x)\n",
    "        x = bn1(x)\n",
    "        x = act1(x)\n",
    "        x = maxpool(x)\n",
    "        stage1_out = layer1(x)  # 第一阶段的输出\n",
    "        features.append(stage1_out)\n",
    "        stage2_out = layer2(stage1_out)  # 第二阶段的输出\n",
    "        features.append(stage2_out)\n",
    "        stage3_out = layer3(stage2_out)  # 第三阶段的输出\n",
    "        features.append(stage3_out)\n",
    "        stage4_out = layer4(stage3_out)  # 第四阶段的输出\n",
    "        features.append(stage4_out)\n",
    "        return tuple(features)\n",
    "\n",
    "    def _modify_layer(self, layer):\n",
    "        \"\"\"\n",
    "        在每个残差块中的 ReLU 前加上 InstanceNorm2d 操作。\n",
    "        \"\"\"\n",
    "        for block in layer:\n",
    "            # 修改 conv1 和 conv2 之后的 ReLU，将 InstanceNorm2d 放在 ReLU 前面\n",
    "            # 对于每个残差块，将 InstanceNorm2d 加入到 ReLU 之前\n",
    "            block.act3 = nn.Sequential(\n",
    "                nn.InstanceNorm2d(block.conv3.out_channels, affine=True),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def _modify_layer_stride(self, last_layer, last_layer_downsample):\n",
    "        # 在最后一层将stride改为1\n",
    "        last_layer.stride = (1, 1)\n",
    "        last_layer_downsample.stride = (1, 1)\n",
    "        \n",
    "    def forward_features(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        # 池化操作，[batch_size, 2048, 7, 7] -> [batch_size, 2048, 1, 1]\n",
    "        x = self.gap(x)\n",
    "        # 展平特征图，将其变为 [batch_size, 2048 * 1 * 1]\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        if not self.feat is None:\n",
    "            x = self.feat(x)\n",
    "        return x\n",
    "\n",
    "class Data_Processor(object):\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transformer = Transforms.Compose([\n",
    "            Transforms.Resize((self.height, self.width)),\n",
    "            Transforms.ToTensor(),\n",
    "            Transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.transformer(img).unsqueeze(0)\n",
    "\n",
    "def cosine_similarity_loss(student_features, teacher_features, alpha=0.5):\n",
    "    \"\"\"\n",
    "    计算余弦相似度损失，主要用于ReID任务中对齐特征。\n",
    "    \n",
    "    :param student_features: 学生模型的特征 (B, 512)\n",
    "    :param teacher_features: 教师模型的特征 (B, 512)\n",
    "    :param alpha: 蒸馏损失的权重，通常在 0-1 之间\n",
    "    :return: 损失值\n",
    "    \"\"\"\n",
    "    # 归一化特征向量\n",
    "    student_features = F.normalize(student_features, p=2, dim=1)\n",
    "    teacher_features = F.normalize(teacher_features, p=2, dim=1)\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    cosine_similarity = F.cosine_similarity(student_features, teacher_features)\n",
    "    \n",
    "    # 损失为 1 - cosine_similarity，越接近1，表示相似度越高，损失越低\n",
    "    loss = 1 - cosine_similarity.mean()\n",
    "    \n",
    "    return loss * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f799eb-b947-42e0-ba21-1d9fd078f9e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "fix_seed = 2024\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "mp.set_start_method('spawn', force=True)  # 设置 'spawn' 方法\n",
    "\n",
    "# 手动创建一个包含参数的命名空间\n",
    "args = argparse.Namespace()\n",
    "args.root_dir_train = \"/homec/xiaolei/projects/ReID/datasets/train\"\n",
    "args.root_dir_valid = \"/homec/xiaolei/projects/ReID/datasets/valid\"\n",
    "args.train_epochs = 100\n",
    "args.batch_size = 256\n",
    "args.num_workers = 10\n",
    "args.height = 224\n",
    "args.width = 224\n",
    "args.resume = False\n",
    "config = get_config(args)\n",
    "stage_train = \"train\"\n",
    "stage_valid = \"valid\"\n",
    "\n",
    "remove_ipynb_checkpoints(args.root_dir_train)\n",
    "remove_ipynb_checkpoints(args.root_dir_valid)\n",
    "\n",
    "train_data_loader = data_provider(args, stage=stage_train)\n",
    "valid_data_loader = data_provider(args, stage=stage_valid)\n",
    "\n",
    "# 初始化教师模型和学生模型\n",
    "teacher_model = SwinTransformerTeacher(num_features=512).cuda()\n",
    "student_model = ResNetStudent(num_features=512).cuda()\n",
    "\n",
    "# 加载教师模型的预训练权重（假设教师模型已经训练好）\n",
    "teacher_weight_path = '/homec/xiaolei/projects/ISR/weights/swin_base_patch4_window7_224.pth'\n",
    "teacher_weight = torch.load(teacher_weight_path)\n",
    "teacher_model.load_state_dict(teacher_weight['state_dict'], strict=True)\n",
    "teacher_model.eval()  # 冻结教师模型\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "if args.resume:\n",
    "    student_model_weight_path = 'weights/student_model_base/best_student_model_0.09995280856817541.pth'\n",
    "    student_model_weight = torch.load(student_model_weight_path)\n",
    "    student_model.load_state_dict(student_model_weight, strict=True)\n",
    "\n",
    "s_loss = dict()\n",
    "# 查看模型可使用的函数\n",
    "# dir(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967254a-ebca-43b9-ad48-27cfe707937e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(student_model.parameters(), lr=1e4)\n",
    "optimizer = build_optimizer(config, student_model)\n",
    "# 学习率优化器\n",
    "lr_scheduler = build_scheduler(config, optimizer, len(train_data_loader))\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# 假设已经定义了 dataloader，并且数据无标签\n",
    "epochs = args.train_epochs  # 设置训练的 epoch 数\n",
    "best_loss = math.inf\n",
    "path = \"/homec/xiaolei/projects/ReID/weights/student_model_base3_strong_reid\"\n",
    "create_directory_if_not_exists(path)\n",
    "\n",
    "# 训练学生模型（无监督）\n",
    "for epoch in range(0, epochs):\n",
    "    student_model.train() \n",
    "    optimizer.zero_grad()\n",
    "    num_steps = len(train_data_loader)\n",
    "    train_loss = []\n",
    "    \n",
    "    # 可视化进度条\n",
    "    with tqdm(total=len(train_data_loader), desc=f\"Epoch {epoch + 1}/{args.train_epochs}\") as pbar:\n",
    "        # 将数据送入模型进行训练\n",
    "        for idx, person_image_bs in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # person_image_bs = torch.cat((person_image_bs[0], person_image_bs[1]), dim=0)\n",
    "            if not isinstance(person_image_bs, torch.Tensor):\n",
    "                person_image_bs = torch.stack(person_image_bs)\n",
    "            # print(f'person_image_bs: {person_image_bs.shape}')\n",
    "            # continue\n",
    "            person_image_bs = person_image_bs.to(device)\n",
    "            # print(type(person_image_bss))\n",
    "            # 通过教师print(f'x: {x.shape}')模型和学生模型获取输出特征\n",
    "            with torch.cuda.amp.autocast():\n",
    "                with torch.no_grad():  # 教师模型保持冻结状态\n",
    "                    teacher_output = teacher_model(person_image_bs)\n",
    "\n",
    "                student_output = student_model(person_image_bs)\n",
    "                \n",
    "                s_loss['ori_loss'] = cosine_similarity_loss(student_output, teacher_output, 1.0)\n",
    "\n",
    "                loss = s_loss['ori_loss']\n",
    "                train_loss.append(loss.item())\n",
    "    \n",
    "            # 反向传播并更新学生模型参数\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            lr_scheduler.step_update(epoch * num_steps + idx)\n",
    "\n",
    "            # 更新进度条\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            pbar.update(1)\n",
    "        \n",
    "        train_loss_avg = np.average(train_loss)\n",
    "        torch.save(student_model.state_dict(), path + '/' + f'checkpoint_{epoch}_{train_loss_avg}.pth')\n",
    "    \n",
    "    # 验证阶段\n",
    "    student_model.eval()\n",
    "    val_output_loss = []\n",
    "    val_feature_loss = []\n",
    "    with tqdm(total=len(valid_data_loader), desc=f\"Epoch {epoch + 1}/{args.train_epochs}\") as pbar:\n",
    "        with torch.no_grad():\n",
    "             for person_image_bs in valid_data_loader:\n",
    "                # person_image_bs = torch.cat((person_image_bs[0], person_image_bs[1]), dim=0)\n",
    "                if not isinstance(person_image_bs, torch.Tensor):\n",
    "                    person_image_bs = torch.stack(person_image_bs)\n",
    "                # print(f'person_image_bs: {person_image_bs.shape}')\n",
    "                # continue\n",
    "                person_image_bs = person_image_bs.to(device)\n",
    "                # 教师\n",
    "                teacher_output = teacher_model(person_image_bs)\n",
    "                # 学生\n",
    "                student_output = student_model(person_image_bs)\n",
    "                \n",
    "                s_loss['ori_loss'] = cosine_similarity_loss(student_output, teacher_output, 1.0)\n",
    "\n",
    "                output_loss = s_loss['ori_loss']\n",
    "                val_output_loss.append(output_loss.item())\n",
    "\n",
    "                # 更新进度条\n",
    "                pbar.set_postfix({'val_output_loss': output_loss.item()})\n",
    "                pbar.update(1)\n",
    "\n",
    "        val_output_loss_avg = np.average(val_output_loss)  # 计算平均验证损失\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss_avg}, Validation Output Loss: {val_output_loss_avg}')\n",
    "\n",
    "    # 保存最优的学生模型\n",
    "    if val_output_loss_avg < best_loss:\n",
    "        best_loss = val_output_loss_avg\n",
    "        temp_best_model_path = os.path.join(path, f\"best_student_model.pth\")\n",
    "        torch.save(student_model.state_dict(), temp_best_model_path)\n",
    "        print(f'Best model saved with Validation Loss: {best_loss}')\n",
    "\n",
    "# 保存训练好的学生模型\n",
    "best_model_path = os.path.join(path, \"student_model.pth\")\n",
    "torch.save(student_model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968258f-2363-44ec-b2cd-39f36efa687b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "swin_model = SwinTransformerTeacher()\n",
    "swin_model = swin_model.to(device)\n",
    "res_model = ResNetStudent()\n",
    "res_model = res_model.to(device)\n",
    "\n",
    "swin_features = swin_model.extract_feat(torch.randn(1, 3, 224, 224).to(device))\n",
    "res_features = res_model.extract_feat(torch.randn(1, 3, 224, 224).to(device))\n",
    "\n",
    "for swin_feature in swin_features:\n",
    "    print(swin_feature.shape)\n",
    "print('='*100)\n",
    "for res_feature in res_features:\n",
    "    print(res_feature.shape)\n",
    "\n",
    "print(res_model(torch.randn(1, 3, 224, 224).to(device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3511fa6-783e-4c50-8130-55e45702c06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openmmlab]",
   "language": "python",
   "name": "conda-env-openmmlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
